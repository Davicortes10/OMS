import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from modelos.avaliacao_modelo import ModelEvaluator
import ace_tools as tools

class LifeExpectancyNN:
    """
    Classe para modelagem de Expectativa de Vida usando Redes Neurais Artificiais (RNA).

    Esta classe realiza:
    - PrÃ©-processamento dos dados (normalizaÃ§Ã£o e encoding).
    - ConstruÃ§Ã£o de um modelo de rede neural `Sequential` com camadas densas.
    - Treinamento, avaliaÃ§Ã£o e prediÃ§Ã£o do modelo.

    Attributes:
        df (pd.DataFrame): O DataFrame contendo os dados para modelagem.
        model (Sequential): O modelo de Rede Neural criado.
    """

    def __init__(self, df: pd.DataFrame):
        """
        Inicializa a classe, realizando a preparaÃ§Ã£o dos dados.

        Args:
            df (pd.DataFrame): O DataFrame com os dados originais.
        """
        if not isinstance(df, pd.DataFrame):
            raise TypeError("âŒ O argumento fornecido deve ser um DataFrame do Pandas.")

        self.df = df.copy()
        self.label_cols = ['Country', 'Status']
        self.scale_cols = [col for col in df.columns if col not in self.label_cols + ['Life expectancy ']]
        
        self.pre_processed_csv = self.preprocess_data(df)
        self.X = self.pre_processed_csv.drop('Life expectancy ', axis=1)
        self.y = self.pre_processed_csv['Life expectancy ']

        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.X, self.y, test_size=0.2, random_state=123
        )

        self.model = self.build_model(input_shape=(self.X_train.shape[1],))
    
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Normaliza os dados numÃ©ricos e aplica Label Encoding Ã s variÃ¡veis categÃ³ricas.

        Returns:
            pd.DataFrame: DataFrame prÃ©-processado.
        """

        le = LabelEncoder()
        mm = MinMaxScaler()

        df[self.scale_cols] = mm.fit_transform(df[self.scale_cols])
        df[self.label_cols] = df[self.label_cols].apply(le.fit_transform)

        return df
    
    def build_model(self, input_shape: tuple) -> Sequential:
        """
        ConstrÃ³i um modelo de Rede Neural `Sequential`.

        Args:
            input_shape (tuple): Shape da entrada do modelo.

        Returns:
            Sequential: Modelo de Rede Neural criado.
        """

        model = Sequential([
            Dense(128, activation='relu', input_shape=input_shape),
            Dense(64, activation='relu'),
            Dense(1, activation='linear')
        ])
        return model
    
    def compile_model(self, optimizer='adam', loss='Huber', metrics=['mae']):
        """
        Compila o modelo com otimizador e funÃ§Ã£o de perda definidos.

        Args:
            optimizer (str): Algoritmo de otimizaÃ§Ã£o (padrÃ£o: Adam).
            loss (str): FunÃ§Ã£o de perda (padrÃ£o: Huber).
            metrics (list): Lista de mÃ©tricas (padrÃ£o: MAE).
        """

        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

    def train_model(self, epochs=1000, batch_size=32, validation_split=0.2):
        """
        Treina o modelo com os dados de treinamento.

        Args:
            epochs (int): NÃºmero de Ã©pocas.
            batch_size (int): Tamanho do batch.
            validation_split (float): Percentual dos dados usados para validaÃ§Ã£o.
        """

        self.model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)
    
    def evaluate_model(self):
        """
        Avalia o desempenho do modelo treinado e exibe as mÃ©tricas de desempenho em formato de tabela.

        A avaliaÃ§Ã£o inclui:
        - AcurÃ¡cia do modelo.
        - RelatÃ³rio de classificaÃ§Ã£o detalhado.
        - Matriz de confusÃ£o.

        Returns:
            None: Apenas exibe os resultados formatados.

        Example:
            >>> model = LifeExpectancyNN(df)
            >>> model.evaluate_model()
        """
        
        # Fazer previsÃµes
        y_pred = self.model.predict(self.X_test).flatten()

        # Calcular mÃ©tricas
        erro_absoluto = np.abs(self.y_test - y_pred)
        erro_relativo = np.abs(erro_absoluto / self.y_test)

        # Criar DataFrame de mÃ©tricas
        metrics_data = {
            "MÃ©trica": ["Erro Absoluto MÃ©dio (MAE)", "Erro Relativo MÃ©dio (MAPE)"],
            "Valor": [np.mean(erro_absoluto), np.mean(erro_relativo) * 100]  # MAPE em porcentagem
        }
        df_metrics = pd.DataFrame(metrics_data)

        # Matriz de confusÃ£o (convertida para DataFrame)
        y_pred_classes = np.round(y_pred)  # Como Ã© um problema de regressÃ£o, arredondamos
        conf_matrix = confusion_matrix(self.y_test, y_pred_classes)
        df_conf_matrix = pd.DataFrame(conf_matrix, index=["Expectativa Baixa", "Expectativa Alta"], columns=["Previsto Baixo", "Previsto Alto"])

        # Exibir tabelas formatadas
        tools.display_dataframe_to_user(name="MÃ©tricas do Modelo", dataframe=df_metrics)
        tools.display_dataframe_to_user(name="Matriz de ConfusÃ£o", dataframe=df_conf_matrix)
        # Criar instÃ¢ncia da classe ModelEvaluator para avaliaÃ§Ã£o detalhada
        avaliacao = ModelEvaluator(self.y_test, y_pred, self.model.history.history)
        avaliacao.executar_avaliacao_completa()
    
    def executar_pipeline(self, epochs=1000, batch_size=32, validation_split=0.2):
        """
        Executa o pipeline completo de modelagem da expectativa de vida.

        Este mÃ©todo inclui as seguintes etapas:
        1. CompilaÃ§Ã£o do modelo com otimizador e funÃ§Ã£o de perda.
        2. Treinamento do modelo nos dados de treinamento.
        3. AvaliaÃ§Ã£o do modelo nos dados de teste.
        4. ExibiÃ§Ã£o das mÃ©tricas de desempenho.

        Args:
            epochs (int, opcional): NÃºmero de Ã©pocas para o treinamento (padrÃ£o: 1000).
            batch_size (int, opcional): Tamanho do batch para treinamento (padrÃ£o: 32).
            validation_split (float, opcional): Percentual dos dados de treino usados para validaÃ§Ã£o (padrÃ£o: 0.2).

        Returns:
            None: Apenas exibe os resultados formatados.

        Example:
            >>> model = LifeExpectancyNN(df)
            >>> model.executar_pipeline(epochs=500, batch_size=64, validation_split=0.3)
        """
        print("\nðŸ”„ Compilando o modelo...")
        self.compile_model()

        print("\nðŸ“Š Iniciando o treinamento do modelo...")
        self.train_model(epochs=epochs, batch_size=batch_size, validation_split=validation_split)

        print("\nâœ… Avaliando o modelo...")
        self.evaluate_model()
