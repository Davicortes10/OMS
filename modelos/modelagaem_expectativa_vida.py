import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from modelos.avaliacao_modelo import Avaliacao

class ExpectativaVidaMLP:
    """
    Classe para modelagem de Expectativa de Vida usando Redes Neurais Artificiais (RNA).

    Esta classe realiza:
    - PrÃ©-processamento dos dados (normalizaÃ§Ã£o e encoding).
    - ConstruÃ§Ã£o de um modelo de rede neural `Sequential` com camadas densas.
    - Treinamento, avaliaÃ§Ã£o e prediÃ§Ã£o do modelo.

    Attributes:
        df (pd.DataFrame): O DataFrame contendo os dados para modelagem.
        model (Sequential): O modelo de Rede Neural criado.
    """

    def __init__(self, df: pd.DataFrame):
        """
        Inicializa a classe, realizando a preparaÃ§Ã£o dos dados.

        Args:
            df (pd.DataFrame): O DataFrame com os dados originais.
        """
        if not isinstance(df, pd.DataFrame):
            raise TypeError("âŒ O argumento fornecido deve ser um DataFrame do Pandas.")

        self.df = df.copy()
        self.label_cols = ['Country', 'Status']
        self.scale_cols = [col for col in df.columns if col not in self.label_cols + ['Life expectancy ']]
        
        self.pre_processed_csv = self.preprocessamento_data(df)
        self.X = self.pre_processed_csv.drop('Life expectancy ', axis=1)
        self.y = self.pre_processed_csv['Life expectancy ']

        self.X_train, self.X_temp, self.y_train, self.y_temp = train_test_split(
            self.X, self.y, test_size=0.4, random_state=123
        )

        self.X_val, self.X_test, self.y_val, self.y_test = train_test_split(
            self.X_temp, self.y_temp, test_size=0.5, random_state=123
        )

        self.normalizar_dados()

        self.model = self.modelando(input_shape=(self.X_train.shape[1],))
    
    def preprocessamento_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Aplica Label Encoding Ã s colunas categÃ³ricas para conversÃ£o em valores numÃ©ricos.

        Args:
            df (pd.DataFrame): DataFrame contendo variÃ¡veis categÃ³ricas.

        Returns:
            pd.DataFrame: DataFrame com colunas categÃ³ricas convertidas.
        """

        le = LabelEncoder()
        
        df[self.label_cols] = df[self.label_cols].apply(le.fit_transform)

        return df
    
    def normalizar_dados(self):
        """
        Aplica normalizaÃ§Ã£o Min-Max apenas ao conjunto de treino e usa os mesmos parÃ¢metros no teste.

        Args:
            None (usa os atributos da classe).

        Returns:
            None (modifica os atributos X_train e X_test in-place).
        """
        
        mm = MinMaxScaler()


        self.X_train = mm.fit_transform(self.X_train)
        self.X_val = mm.transform(self.X_val)
        self.X_test = mm.transform(self.X_test)
    
    def modelando(self, input_shape: tuple) -> Sequential:
        """
        ConstrÃ³i um modelo de Rede Neural `Sequential`.

        Args:
            input_shape (tuple): Shape da entrada do modelo.

        Returns:
            Sequential: Modelo de Rede Neural criado.
        """

        model = Sequential([
            Dense(128, activation='relu', input_shape=input_shape),
            Dense(64, activation='relu'),
            Dense(1, activation='linear')
        ])
        return model
    
    def compilando(self, optimizer='adam', loss='Huber', metrics=['mae']):
        """
        Compila o modelo com otimizador e funÃ§Ã£o de perda definidos.

        Args:
            optimizer (str): Algoritmo de otimizaÃ§Ã£o (padrÃ£o: Adam).
            loss (str): FunÃ§Ã£o de perda (padrÃ£o: Huber).
            metrics (list): Lista de mÃ©tricas (padrÃ£o: MAE).
        """

        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

    def treinando(self, epochs=1000, batch_size=32):
        """
        Treina o modelo com os dados de treinamento.

        Args:
            epochs (int): NÃºmero de Ã©pocas.
            batch_size (int): Tamanho do batch.
            validation_split (float): Percentual dos dados usados para validaÃ§Ã£o.
        """

        self.model.fit(
            self.X_train, self.y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=(self.X_val, self.y_val) 
        )
    
    def avaliando(self):
        """
        Avalia o desempenho do modelo treinado e exibe mÃ©tricas de desempenho para regressÃ£o.

        A avaliaÃ§Ã£o inclui:
        - Erro Absoluto MÃ©dio (MAE)
        - Erro Relativo MÃ©dio (MAPE)
        - RÂ² Score (Coeficiente de DeterminaÃ§Ã£o)
        - AnÃ¡lise visual da distribuiÃ§Ã£o de erros.

        Returns:
            None: Apenas exibe os resultados formatados.

        Example:
            >>> model = LifeExpectancyNN(df)
            >>> model.evaluate_model()
        """

        # Fazer previsÃµes
        y_pred = self.model.predict(self.X_test).flatten()

        # Calcular mÃ©tricas apropriadas para regressÃ£o
        erro_absoluto = np.abs(self.y_test - y_pred)
        erro_relativo = np.abs(erro_absoluto / self.y_test)
        r2 = r2_score(self.y_test, y_pred)

        # Criar DataFrame de mÃ©tricas
        df_metrics = pd.DataFrame({
            "MÃ©trica": ["Erro Absoluto MÃ©dio (MAE)", "Erro Relativo MÃ©dio (MAPE)", "RÂ² Score"],
            "Valor": [np.mean(erro_absoluto), np.mean(erro_relativo) * 100, r2]
        })

        # Exibir mÃ©tricas no console
        print("\nðŸ“Š **MÃ©tricas do Modelo:**")
        print(df_metrics)

        # Criar instÃ¢ncia da classe ModelEvaluator para anÃ¡lises visuais
        avaliacao =  Avaliacao(self.y_test, y_pred, self.model.history.history)
        
        print("\nðŸ“Š **Gerando anÃ¡lises visuais...**")
        avaliacao.executar_avaliacao_completa()

        print("\nâœ… **AvaliaÃ§Ã£o do modelo finalizada!** ðŸš€")
    
    def executar_pipeline(self, epochs=1000, batch_size=32, validation_split=0.2):
        """
        Executa o pipeline completo de modelagem da expectativa de vida.

        Este mÃ©todo inclui as seguintes etapas:
        1. CompilaÃ§Ã£o do modelo com otimizador e funÃ§Ã£o de perda.
        2. Treinamento do modelo nos dados de treinamento.
        3. AvaliaÃ§Ã£o do modelo nos dados de teste.
        4. ExibiÃ§Ã£o das mÃ©tricas de desempenho.

        Args:
            epochs (int, opcional): NÃºmero de Ã©pocas para o treinamento (padrÃ£o: 1000).
            batch_size (int, opcional): Tamanho do batch para treinamento (padrÃ£o: 32).
            validation_split (float, opcional): Percentual dos dados de treino usados para validaÃ§Ã£o (padrÃ£o: 0.2).

        Returns:
            None: Apenas exibe os resultados formatados.

        Example:
            >>> model = LifeExpectancyNN(df)
            >>> model.executar_pipeline(epochs=500, batch_size=64, validation_split=0.3)
        """
        print("\nðŸ”„ Compilando o modelo...")
        self.compilando()

        print("\nðŸ“Š Iniciando o treinamento do modelo...")
        self.treinando(epochs=epochs, batch_size=batch_size, validation_split=validation_split)

        print("\nâœ… Avaliando o modelo...")
        self.avaliando()
